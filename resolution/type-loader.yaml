# Type Definition Loader
# Load type definitions from remote GitHub repositories
#
# Fetching primitives: see resolution/fetch-patterns.yaml (loaded during bootstrap Phase 3.0)

schema_version: "2.0"
category: resolution

resolution:
  type_loader:
    description:
      brief: Load type definitions from remote GitHub repositories
      detail: |
        Workflows reference type definitions via the definitions block.
        The type loader fetches these definitions from GitHub and builds
        a TypeRegistry that the execution engine uses to dispatch
        consequences and evaluate preconditions.

        Supports version pinning for reproducible builds and extension
        loading for custom type definitions.

    source_format:
      # Base patterns and detection: see resolution/fetch-patterns.yaml
      version_formats:
        - format: "@v2.0.0"
          behavior: Exact version (recommended)
        - format: "@v2.0"
          behavior: Latest patch in v2.0.x
        - format: "@v2"
          behavior: Latest minor in v2.x.x

    loading_algorithm:
      description: Main loading function for type definitions (supports local and remote)
      # Uses parse_source() and fetch() from resolution/fetch-patterns.yaml
      effect: |
        FUNCTION load_types(definitions_block):
            # 1. Parse source (returns {is_local, local_path} or {owner, repo, version})
            source = definitions_block.source
            parts = parse_source(source)

            # 2. Fetch index files (routes to local/gh api/raw URL based on source type)
            consequences_index = fetch(parts, "consequences/index.yaml")
            preconditions_index = fetch(parts, "preconditions/index.yaml")

            # 3. Build registry from indexes
            registry = build_registry(consequences_index, preconditions_index, parts)

            # 4. Load extensions
            IF definitions_block.extensions:
                FOR each ext IN definitions_block.extensions:
                    ext_registry = load_types({ source: ext })
                    registry = merge_registry(registry, ext_registry)

            RETURN registry

    index_format:
      description: Structure of type index files (consolidated v2.0 format)
      example: |
        # consequences/index.yaml
        schema_version: "2.0"
        definition_file: consequences.yaml  # All types in one file

        # Optional remote extensions
        remote_sources:
          # - url: https://raw.githubusercontent.com/.../consequences.yaml
          #   types: [custom_type_1, custom_type_2]

        types:
          set_flag:
            category: core/state
            brief: Set a boolean flag
            required_params: [flag, value]
          clone_repo:
            category: extensions/git
            brief: Clone git repository
            required_params: [url, dest]
          # ... all types with metadata

        stats:
          total_types: 45
          core_types: 31
          extension_types: 14

      fields:
        - name: schema_version
          required: true
          description: Schema version (semver major.minor)
        - name: definition_file
          required: true
          description: Path to consolidated definition file (relative to index)
        - name: remote_sources
          required: false
          description: Optional list of remote type extensions
        - name: types
          required: true
          description: Type registry with category, brief, and required_params
        - name: stats
          required: false
          description: Statistics for quick reference

    registry_building:
      description: Build TypeRegistry from index files (v2.0 format)
      effect: |
        FUNCTION build_registry(consequences_index, preconditions_index, source_parts):
            registry = {
                consequences: {
                    _index: consequences_index  # Cache index for lazy loading
                },
                preconditions: {
                    _index: preconditions_index
                },
                source: source_parts  # {owner, repo, version} for fetching
            }

            # Build type lookup from v2.0 index format
            FOR each type_name, type_info IN consequences_index.types:
                registry.consequences[type_name] = {
                    category: type_info.category,
                    brief: type_info.brief,
                    required_params: type_info.required_params,
                    loaded: false  # Lazy load full definition
                }

            FOR each type_name, type_info IN preconditions_index.types:
                registry.preconditions[type_name] = {
                    category: type_info.category,
                    brief: type_info.brief,
                    required_params: type_info.required_params,
                    loaded: false
                }

            RETURN registry

      result_structure: |
        type_registry:
          schema_version: "2.0"

          consequences:
            _index:
              definition_file: consequences.yaml
            set_flag:
              category: core/state
              brief: Set a boolean flag
              required_params: [flag, value]
              loaded: false
            # ... all consequence types

          preconditions:
            _index:
              definition_file: preconditions.yaml
            file_exists:
              category: core/filesystem
              brief: Check if arbitrary file exists
              required_params: [path]
              loaded: false
            # ... all precondition types

    lazy_loading:
      description: Load full type definitions on first use (consolidated file approach)
      effect: |
        FUNCTION get_type_definition(registry, type_name, kind):
            # kind is "consequences" or "preconditions"
            entry = registry[kind][type_name]

            IF NOT entry:
                THROW "Unknown {kind} type: {type_name}"

            IF NOT entry.loaded:
                # Get definition_file from cached index
                definition_file = registry[kind]._index.definition_file
                path = "{kind}/" + definition_file

                # Fetch consolidated file (routes to local/gh api/raw URL based on source type)
                definitions = fetch(registry.source, path)

                # Cache all definitions from this file (since they're consolidated)
                FOR each name, def IN definitions.types:
                    IF name IN registry[kind]:
                        registry[kind][name].definition = def
                        registry[kind][name].loaded = true

            RETURN entry.definition

      note: |
        The v2.0 consolidated format stores all type definitions in a single file
        per kind (e.g., consequences/consequences.yaml) rather than separate files
        per category. This reduces fetch count from O(categories) to O(1) per kind.

    selective_loading:
      description: Workflow-first selective type loading for optimized fetching
      rationale: |
        For workflows using only a few types (e.g., 5-10 out of 77 total), we can
        analyze the workflow first to identify needed types, then use a single yq
        query to extract only those types from the consolidated file.

      workflow_analysis:
        description: Extract all type references from a workflow
        effect: |
          FUNCTION extract_workflow_types(workflow):
              consequences = Set()
              preconditions = Set()

              # Entry preconditions
              FOR each precondition IN workflow.entry_preconditions:
                  extract_precondition_types(precondition, preconditions)

              # All nodes
              FOR each node IN workflow.nodes:
                  IF node.type == "action":
                      FOR each action IN node.actions:
                          consequences.add(action.type)

                  ELSE IF node.type == "conditional":
                      extract_precondition_types(node.condition, preconditions)

                  ELSE IF node.type == "user_prompt":
                      FOR each handler IN node.on_response:
                          IF handler.consequence:
                              FOR each c IN handler.consequence:
                                  consequences.add(c.type)

                  ELSE IF node.type == "validation_gate":
                      FOR each validation IN node.validations:
                          extract_precondition_types(validation.condition, preconditions)
                          IF validation.on_failure:
                              FOR each c IN validation.on_failure:
                                  consequences.add(c.type)

              RETURN {consequences, preconditions}

          FUNCTION extract_precondition_types(precondition, set):
              set.add(precondition.type)
              # Recurse into composites (all_of, any_of, xor_of, none_of)
              IF precondition.conditions:
                  FOR each nested IN precondition.conditions:
                      extract_precondition_types(nested, set)

      yq_query_construction:
        description: Build single yq query to extract multiple types from consolidated file
        effect: |
          FUNCTION build_selective_yq_query(type_names, root_key):
              conditions = type_names.map(n => '.key == "' + n + '"').join(" or ")
              RETURN ".{root_key} | with_entries(select({conditions}))"

        examples:
          - input:
              type_names: ["set_flag", "clone_repo"]
              root_key: "consequences"
            output: '.consequences | with_entries(select(.key == "set_flag" or .key == "clone_repo"))'

      selective_fetch:
        description: Fetch only needed types using yq filtering - supports local, gh api, and raw URL
        effect: |
          FUNCTION fetch_selective_types(source_parts, type_names, kind):
              query = build_selective_yq_query(type_names, kind)
              path = "{kind}/{kind}.yaml"

              IF source_parts.is_local:
                  RETURN fetch_selective_local(source_parts.local_path, path, query)
              ELSE:
                  result = fetch_selective_gh_api(source_parts, path, query)
                  IF result.success:
                      RETURN result

                  result = fetch_selective_raw_url(source_parts, path, query)
                  IF result.success:
                      RETURN result

                  THROW "Failed to fetch selective types from all sources"

        local_method:
          description: Read local file and apply yq filter directly
          effect: |
            FUNCTION fetch_selective_local(local_path, path, query):
                full_path = "{local_path}/{path}"

                IF NOT file_exists(full_path):
                    RETURN { success: false, error: "File not found: {full_path}" }

                result = CALL Bash with:
                    command: |
                        yq eval '{query}' {full_path}

                IF result.exit_code != 0:
                    RETURN { success: false, error: result.stderr }

                RETURN { success: true, content: parse_yaml(result.stdout) }

        gh_api_method:
          description: Fetch via gh api and pipe through yq filter
          effect: |
            FUNCTION fetch_selective_gh_api(source_parts, path, query):
                owner = source_parts.owner
                repo = source_parts.repo
                version = source_parts.version

                result = CALL Bash with:
                    command: |
                        gh api repos/{owner}/{repo}/contents/{path}?ref={version} \
                            --jq '.content' | base64 -d | yq eval '{query}' -

                IF result.exit_code != 0:
                    RETURN { success: false, error: result.stderr }

                RETURN { success: true, content: parse_yaml(result.stdout) }

        raw_url_method:
          description: Fetch via raw URL, write to temp file, apply yq filter
          effect: |
            FUNCTION fetch_selective_raw_url(source_parts, path, query):
                owner = source_parts.owner
                repo = source_parts.repo
                version = source_parts.version

                url = "https://raw.githubusercontent.com/{owner}/{repo}/{version}/{path}"

                response = CALL WebFetch with:
                    url: url
                    prompt: "Return the raw YAML content"

                IF response.status >= 400:
                    RETURN { success: false, error: "{response.status} {url}" }

                IF response.redirect_url:
                    response = CALL WebFetch with:
                        url: response.redirect_url
                        prompt: "Return the raw YAML content"

                temp_file = write_temp_file(response.content)
                result = CALL Bash with:
                    command: |
                        yq eval '{query}' {temp_file}

                IF result.exit_code != 0:
                    RETURN { success: false, error: result.stderr }

                RETURN { success: true, content: parse_yaml(result.stdout) }

      main_algorithm:
        description: Complete selective loading algorithm (supports local and remote sources)
        effect: |
          FUNCTION load_types_selective(definitions_block, workflow):
              # 1. Parse source
              source = definitions_block.source
              parts = parse_source(source)

              # 2. Fetch index files (lightweight, always needed)
              consequences_index = fetch(parts, "consequences/index.yaml")
              preconditions_index = fetch(parts, "preconditions/index.yaml")

              # 3. Analyze workflow to find needed types
              needed = extract_workflow_types(workflow)

              # 4. Validate all needed types exist in indexes
              FOR each type_name IN needed.consequences:
                  IF type_name NOT IN consequences_index.types:
                      THROW "Unknown consequence type: {type_name}"

              FOR each type_name IN needed.preconditions:
                  IF type_name NOT IN preconditions_index.types:
                      THROW "Unknown precondition type: {type_name}"

              # 5. Selective fetch with yq filtering
              consequence_defs = fetch_selective_types(
                  parts, needed.consequences, "consequences"
              )

              precondition_defs = fetch_selective_types(
                  parts, needed.preconditions, "preconditions"
              )

              # 6. Build minimal registry with only needed types
              registry = {
                  consequences: {},
                  preconditions: {},
                  source: parts
              }

              FOR each type_name IN needed.consequences:
                  registry.consequences[type_name] = {
                      category: consequences_index.types[type_name].category,
                      brief: consequences_index.types[type_name].brief,
                      required_params: consequences_index.types[type_name].required_params,
                      definition: consequence_defs[type_name],
                      loaded: true
                  }

              FOR each type_name IN needed.preconditions:
                  registry.preconditions[type_name] = {
                      category: preconditions_index.types[type_name].category,
                      brief: preconditions_index.types[type_name].brief,
                      required_params: preconditions_index.types[type_name].required_params,
                      definition: precondition_defs[type_name],
                      loaded: true
                  }

              # 7. Handle extensions (if any)
              IF definitions_block.extensions:
                  FOR each ext IN definitions_block.extensions:
                      ext_registry = load_types_selective({ source: ext }, workflow)
                      registry = merge_registry(registry, ext_registry)

              RETURN registry

    hybrid_loading:
      description: Automatically choose optimal loading strategy based on workflow complexity
      threshold: 30  # types

      effect: |
        FUNCTION load_types_hybrid(definitions_block, workflow):
            # Analyze workflow to count needed types
            needed = extract_workflow_types(workflow)
            total = needed.consequences.size + needed.preconditions.size

            # Choose strategy based on type count
            IF total > 30:
                LOG "Using lazy loading strategy ({total} types needed)"
                RETURN load_types(definitions_block)  # Lazy loading approach
            ELSE:
                LOG "Using selective loading strategy ({total} types needed)"
                RETURN load_types_selective(definitions_block, workflow)

      integration_point: |
        The execution engine calls load_types_hybrid() when initializing a workflow,
        passing both the definitions block and the parsed workflow. This allows
        automatic strategy selection without workflow author intervention.

    strategy_comparison:
      table: |
        | Strategy  | Upfront Cost | First Use Cost | Best For         | Fetches          |
        |-----------|-------------|----------------|------------------|------------------|
        | Lazy      | Low (indexes) | High (~2500 lines) | >30 types     | 2 + 1-2 on use  |
        | Selective | Medium      | None (pre-loaded)  | <30 types     | 2 + 2 selective  |

    extension_loading:
      description: Load additional type sources
      usage: |
        definitions:
          source: hiivmind/hiivmind-blueprint-lib@v2.0.0
          extensions:
            - mycorp/custom-types@v1.0.0

      merge_strategy:
        description: Merge extension types into base registry
        effect: |
          FUNCTION merge_registry(base, extension):
              result = copy(base)

              FOR each type_name, entry IN extension.consequences:
                  IF type_name IN result.consequences:
                      # Collision - require namespace prefix
                      namespaced_name = "{extension.source}:{type_name}"
                      result.consequences[namespaced_name] = entry
                  ELSE:
                      result.consequences[type_name] = entry

              FOR each type_name, entry IN extension.preconditions:
                  IF type_name IN result.preconditions:
                      namespaced_name = "{extension.source}:{type_name}"
                      result.preconditions[namespaced_name] = entry
                  ELSE:
                      result.preconditions[type_name] = entry

              RETURN result

      namespaced_usage: |
        # When collisions exist, use namespace prefix
        nodes:
          my_action:
            type: action
            actions:
              # Base type (unambiguous)
              - type: set_flag
                flag: ready
                value: true

              # Namespaced type (collision resolved)
              - type: mycorp/custom-types:clone_repo
                url: "${internal_repo}"

    validation:
      description: Validate workflow types after loading
      effect: |
        FUNCTION validate_workflow_types(workflow, registry):
            # Check all consequence types in action nodes
            FOR each node IN workflow.nodes:
                IF node.type == "action":
                    FOR each action IN node.actions:
                        IF action.type NOT IN registry.consequences:
                            THROW "Unknown consequence type: {action.type}"

                IF node.type == "conditional":
                    validate_precondition_type(node.condition, registry)

            # Check entry preconditions
            FOR each precondition IN workflow.entry_preconditions:
                validate_precondition_type(precondition, registry)

        FUNCTION validate_precondition_type(precondition, registry):
            IF precondition.type NOT IN registry.preconditions:
                THROW "Unknown precondition type: {precondition.type}"

            # Recursively check composite conditions
            IF precondition.type IN ["all_of", "any_of", "xor_of", "none_of"]:
                FOR each cond IN precondition.conditions:
                    validate_precondition_type(cond, registry)

    error_messages:
      examples:
        - error: "Failed to resolve type definitions (remote)"
          context: |
            Source: hiivmind/hiivmind-blueprint-lib@v2.0.0

            Tried:
            1. gh api repos/.../consequences/index.yaml → (error)
            2. raw.githubusercontent.com fallback → (error)

            Suggestions:
            - Verify gh auth status (gh auth status)
            - Check the version exists: https://github.com/hiivmind/hiivmind-blueprint-lib/tags

        - error: "Failed to resolve type definitions (local)"
          context: |
            Source: ./lib/types

            Tried:
            1. {local_path}/consequences/index.yaml → File not found

            Suggestions:
            - Verify the path exists: ls -la ./lib/types
            - Check for required files: consequences/index.yaml, preconditions/index.yaml

    since: "2.0.0"
